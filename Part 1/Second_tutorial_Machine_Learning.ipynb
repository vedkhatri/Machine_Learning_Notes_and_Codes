{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'frame', 'categories', 'feature_names', 'target_names', 'DESCR', 'details', 'url'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "mnist = fetch_openml('mnist_784', version = 1)\n",
    "mnist.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70000, 784)\n",
      "(70000,)\n"
     ]
    }
   ],
   "source": [
    "X, y = mnist['data'], mnist['target']\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "some_digit = X[7000]\n",
    "some_data_image = some_digit.reshape(28,28)\n",
    "\n",
    "plt.imshow(some_data_image, cmap = mpl.cm.binary, interpolation = \"nearest\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "print(y[7000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y is in the form of a string, converting it to an integer,\n",
    "import numpy as np\n",
    "y = y.astype(np.uint8)\n",
    "\n",
    "# To create a train and a test set,\n",
    "\n",
    "X_train, X_test, y_train, y_test = X[:60000], X[60000:], y[:60000], y[60000:]\n",
    "# In this exercise, the first 60,000 instances (images) are used for training and the remaining 10,000 for testing.\n",
    "# The data is already shuffled, which in this case, would ensure that all cross-validation being similar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training a binary classifier,\n",
    "\n",
    "# Trying instances containing 7 (Note: Binary would verify if an instance would or would not meet the condition)\n",
    "y_train_7 = (y_train == 7)    # True for all 7s, False for all other instances\n",
    "y_test_7 = (y_test == 7)\n",
    "\n",
    "# Picking a classifier and training it,\n",
    "from sklearn.linear_model import SGDClassifier    # Using the Stichastic Gradient Descent Classifier\n",
    "sgd_clf = SGDClassifier(random_state = 42)\n",
    "sgd_clf.fit(X_train, y_train_7)\n",
    "\n",
    "# Let's check the classifier by an instance,\n",
    "sgd_clf.predict([some_digit])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.98105, 0.9735 , 0.95335])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cross-validating the model with K-fold cross-validation technique,\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "cross_val_score(sgd_clf, X_train, y_train_7, cv = 3, scoring = \"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.89535, 0.8984 , 0.893  ])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's try a different model than SGD\n",
    "# Let's try BaseEstimator\n",
    "\n",
    "from sklearn.base import BaseEstimator\n",
    "\n",
    "class Never7Classifier(BaseEstimator):\n",
    "    def fit(self, X, y = None):\n",
    "        pass\n",
    "    def predict(self, X):\n",
    "        return np.zeros((len(X), 1), dtype = bool)\n",
    "\n",
    "never_7_clf = Never7Classifier()\n",
    "cross_val_score(never_7_clf, X_train, y_train_7, cv = 3, scoring = \"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A much efficient way to check the accuracy is to compute the 'confusion matrix'.\n",
    "# The general idea is to count the number of instance the class A was classified as class B\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "y_train_pred = cross_val_score(sgd_clf, X_train, y_train, cv = 3)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_train_7, y_train_pred)\n",
    "\n",
    "# The output contains a 2x2 array: The first row considers non-7 images (negative class), where the first element is\n",
    "# the number of correctly classified instances (true negatives) and the second element as wrongly classified (false\n",
    "# negatives). The second row consists of the first element as wrongly classfied 7s (false positives) and the second\n",
    "# element consists of correctly classfied 7s (true positives)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# While the confusion matrix would give the information required, a measure called 'precision' of a classifier can be\n",
    "# derived from the confusion matrix. This accurately describes the positive predictions.\n",
    "\n",
    "# A mathematical formula is precision = TP / (TP + FP), where TP - true positive, FP - false positive\n",
    "\n",
    "# For further accuracy, another measure called 'recall' or 'sensitivity' or 'true positive rate' (TPR) is used along with\n",
    "# the precision measure.\n",
    "\n",
    "# recall = TP + (TP + FN), where TP - True Positive, FN - False Negative\n",
    "\n",
    "# Computing precision and recall,\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "precision_score(y_train_7, y_train_pred)\n",
    "recall_score(y_train_7, y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_train_7' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-e0c60e73fe1e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;31m# f1 is computed as,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mf1_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train_7\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'y_train_7' is not defined"
     ]
    }
   ],
   "source": [
    "# It is often convenient to combine precision and recall into a single matrix called f1 score. The f1 score is the harmonic\n",
    "# mean of precision and recall.\n",
    "# Whilst the regular mean treats all values equally, a harmonic mean gives much more weight to low values.\n",
    "# As a result, the classifier f1 will only get a hogh score if both precision and recall are high.\n",
    "\n",
    "# The mathematical formula for f1 is:\n",
    "# f1 = 2 / ( 1/precision + 1/recall) == TP/ (TP + ((FN + FP)/2))\n",
    "\n",
    "# f1 is computed as,\n",
    "from sklearn.metrics import f1_score\n",
    "f1_score(y_train_7, y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With the type of the problem, it may be beneficial to increase or reduce precision or\n",
    "# recall"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
